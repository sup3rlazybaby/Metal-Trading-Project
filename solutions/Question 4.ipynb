{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b399eda5",
   "metadata": {},
   "source": [
    "**Objective**: Async Data Pipeline\n",
    "\n",
    "**Tasks**:\n",
    "- Modify Question 3 to write data to the database asynchronously .\n",
    "- Read from the database 5 times concurrantly using async (hint: asyncio.gather())."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197ed90a",
   "metadata": {},
   "source": [
    "# Task: Modify Question 3 to write data to the database asynchronously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bd58d8",
   "metadata": {},
   "source": [
    "For continuity, SQLAlchemy is used for both synchronous and asynchronous database operations. This helps to create a unified codebase and easier maintenance. \n",
    "The asyncio library is used for to create an asynchronous data pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70acbbab",
   "metadata": {},
   "source": [
    "To prevent any interference with the database used in Question 3, a duplicate database named `metal_commodity_Q4.db` is created for the current database interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ba81f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import asyncio\n",
    "from sqlalchemy import create_engine, select, Column, Integer, String, Float, Date\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine, async_sessionmaker\n",
    "from sqlalchemy.orm import sessionmaker, DeclarativeBase\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from functools import wraps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b216c2f2-006b-4788-a329-4ce0f13868c0",
   "metadata": {},
   "source": [
    "## Design of asynchronous data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6475998f-1077-49cc-9122-39f0b83a90c7",
   "metadata": {},
   "source": [
    "The synchronous code written in Question 3 is adapted to run tasks asynchronously using the constructs and features provided by `asyncio` libarary:\n",
    "- `async`: Functions used in coroutines are defined with `async def` syntax to indicates they can be sustepnded and resumed asynchronously.\n",
    "- `await`: Inside these functions, asynchronous operations are marked with the `await` to allow programe to pause execution until the awaited operation completes.\n",
    "- `async with` is used to manage database connection and file handles. This allows efficient resource management and ensure proper clean up after asynchronous operation is complete.\n",
    "- `asyncio.run(main())` is the central component of asyncio. It initializes the event loop (if one is not already running), executes the provided asynchronous main function, and then closes the event loop once the main function completes. Note that this syntax isn't directly usable in Jupyter notebook due to certain limitations, which we'll discuss along with a workaround."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a084b17-bcdf-46f3-941e-60177c73cd29",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e654870",
   "metadata": {},
   "source": [
    "To start, we'll configure logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1910950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(filename='sql_inserts_Q4.log', level=logging.INFO,\n",
    "                    format='%(asctime)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bd90c7",
   "metadata": {},
   "source": [
    "Next, we'll create SQLAlchemy engine for asynchronous operations, using additional `aiosqlite` as async driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3114021",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_async_engine('sqlite+aiosqlite:///metal_commodity_Q4.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369fb26e",
   "metadata": {},
   "source": [
    "Next, the ORM classes, function for logging and functions to calculate MACD and RSI are to be created in the same way as in Question 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5333dab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Base class for declarative ORM\n",
    "class Base(DeclarativeBase):\n",
    "    pass\n",
    "\n",
    "# Define MetalPrice ORM class\n",
    "class MetalPrice(Base):\n",
    "    __tablename__ = 'metal_prices'\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    date = Column(Date)\n",
    "    metal = Column(String)\n",
    "    price = Column(Float)\n",
    "    macd = Column(Float)\n",
    "    macd_signal = Column(Float)\n",
    "    rsi = Column(Float)\n",
    "\n",
    "# Define decorator to log SQL operations\n",
    "def log_sql(func):\n",
    "    @wraps(func)    # Preserve metadata of original function, helps debugging\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = datetime.now()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = datetime.now()\n",
    "        execution_time = end_time - start_time\n",
    "        logging.info(f\"SQL operation {func.__name__} executed in {execution_time.total_seconds()} seconds (asynchronous)\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# Function to calculate MACD for a series of prices\n",
    "def calculate_macd(prices, slow_period=26, fast_period=12, signal_period=9):\n",
    "    slow_ema = prices.ewm(span=slow_period).mean()\n",
    "    fast_ema = prices.ewm(span=fast_period).mean()\n",
    "    macd_line = fast_ema - slow_ema\n",
    "    signal_line = macd_line.ewm(span=signal_period).mean()\n",
    "    return macd_line, signal_line\n",
    "\n",
    "# Function to calculate RSI for a series of prices\n",
    "def calculate_rsi(prices, window=14):\n",
    "    delta = prices.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "# Function to read CSV file and calculate MACD and RSI\n",
    "def calculate_macd_rsi(csv_file):\n",
    "    # Read CSV file into DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Convert 'Dates' column to datetime\n",
    "    df['Dates'] = pd.to_datetime(df['Dates'])\n",
    "\n",
    "    # Extract metal column names\n",
    "    metals = df.columns[1:]\n",
    "\n",
    "    # Iterate over metal columns and calculate MACD, RSI\n",
    "    for metal in metals:\n",
    "        prices = df[metal]\n",
    "        macd_line, macd_signal = calculate_macd(prices)\n",
    "        rsi = calculate_rsi(prices)\n",
    "        df[f'{metal}_macd'] = macd_line\n",
    "        df[f'{metal}_macd_signal'] = macd_signal\n",
    "        df[f'{metal}_rsi'] = rsi\n",
    "\n",
    "    return (df, metals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c928d82f-46df-4a6f-af4f-0fc03b3c1c86",
   "metadata": {},
   "source": [
    "Next, the `populate_sql_table` function is to be modified to leverage asyncio for asynchronous execution:\n",
    "-  `async def` syntax is used to define it as an asynchronous coroutine.\n",
    "-  `async with` is used wit asynchronous session (`async_session`). \n",
    "-  `await` is used to suspend all execution in `populate_sql_table` until `session.commit()` is performed. In the meantime, the event loop could run other asynchronous tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d934fbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to populate SQL table with calculated data\n",
    "@log_sql\n",
    "async def populate_sql_table(df, metals):\n",
    "    # Create session\n",
    "    async_session = async_sessionmaker(bind=engine, expire_on_commit=False)  # Allowing access post-commit, no need for refresh\n",
    "    async with async_session() as session:\n",
    "\n",
    "        # Iterate over DataFrame rows and insert into SQL table\n",
    "        for index, row in df.iterrows():\n",
    "            date = row['Dates']\n",
    "            for metal in metals:\n",
    "                price = row[metal]\n",
    "                macd = row[f'{metal}_macd']\n",
    "                macd_signal = row[f'{metal}_macd_signal']\n",
    "                rsi = row[f'{metal}_rsi']\n",
    "\n",
    "                metal_price = MetalPrice(date=date, metal=metal, price=price,\n",
    "                                        macd=macd, macd_signal=macd_signal, rsi=rsi)\n",
    "                session.add(metal_price)\n",
    "\n",
    "        # Commit changes\n",
    "        await session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15a3ff3",
   "metadata": {},
   "source": [
    "Then we'll define the `main_write()` function to perform calculations with `calculate_macd_rsi` and call `populate_sql_table()` and awaits its completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f489d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the async processing function\n",
    "async def main_write():\n",
    "    # Read CSV file and calculate MACD, RSI\n",
    "    csv_file = 'MarketData_filtered.csv'\n",
    "    df, metals =  calculate_macd_rsi(csv_file)\n",
    "    \n",
    "    # Populate SQL table with calculated data\n",
    "    await populate_sql_table(df, metals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e601e4f-15dc-4749-95a3-e718d9516a4e",
   "metadata": {},
   "source": [
    "Finally, we'll execute the asyncio loop. Note that in a Jupyter notebook, the syntax for executing the loop differs from running a script. \n",
    "- In Jupyter notebooks, code runs within a single-threaded event loop. Thus, we employ `await main()` to ensure efficient processing of requests without blocking the notebook.\n",
    "- In contrast, when running a Python script, a new event loop is created. Therefore, we can simply use `asyncio.run(main_write())` to execute the asyncio loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8e933aa-c724-4bb6-b6b6-385069c5a548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the asyncio event loop from Jupyter notebook\n",
    "await main_write()\n",
    "\n",
    "# Execute the asyncio event loop from Python script\n",
    "# asyncio.run(main_write())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5088bb97-ba6d-4f54-9713-ab965bf3edd8",
   "metadata": {},
   "source": [
    "Note that as a consequence of writing new data to the database, duplicates of existing rows from Question 3 are appended to `metal_commodity_Q4.db`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb3c2ef",
   "metadata": {},
   "source": [
    "# Task: Read from the database 5 times concurrantly using async."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd4ed2b-e815-44db-a55f-3bb3dd3b3227",
   "metadata": {},
   "source": [
    "### Design of asynchronous structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b49ab70-a7a3-431b-b3e3-de2c3287dbe5",
   "metadata": {},
   "source": [
    "We'll create 5 separate database queries and execute them simultaneously with `asyncio.gather`.\n",
    "- `read_data` function reads data from the database asynchronously using an input query.\n",
    "- `concurrent_reads` function orchestrates concurrent execution of multiple database read tasks and aggregate the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301609fa-1de2-44bc-9a25-d11446baea4f",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ca6206",
   "metadata": {},
   "source": [
    "First, we'll define async session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9c42665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define async session\n",
    "async_session = async_sessionmaker(bind=engine, expire_on_commit=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec720c4",
   "metadata": {},
   "source": [
    "Next, we'll define an async function `read_data` to asynchronously execute a database query. Here, the even loop waits until the interact database is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efbb443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async function to read data from the database\n",
    "async def read_data(query):\n",
    "    async with async_session() as session:\n",
    "        result = await session.execute(query)\n",
    "        data = result.fetchall()        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a583d",
   "metadata": {},
   "source": [
    "Then, we'll create `concurrent_reads()` function to create list of queries to be run concurrently.\n",
    "- It creates a list of queries and used `read_data` to asynchronously execute the query and fetch the data.\n",
    "- `asyncio.gather()` function schedules all the tasks to run concurrently in the event loop.\n",
    "- By using `await`, the execution of the current coroutine is suspended until all tasks passed to `asyncio.gather()` are complete and the `results` are returned.\n",
    "\n",
    "To validate the query outputs, we'll deliberately select queries expected to return a limited number of rows from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e3faf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async function to perform concurrent database reads 5 times\n",
    "async def concurrent_reads():\n",
    "    queries = [\n",
    "        select(MetalPrice).where(MetalPrice.date == '2021-01-01'),      # Should return 4 database rows, 2 for each metal\n",
    "        select(MetalPrice).where(MetalPrice.id == 1),                   # Should return 1 database row\n",
    "        select(MetalPrice).where(MetalPrice.metal == 'TIN'),            # Should return 0 database row\n",
    "        select(MetalPrice).where(MetalPrice.id == 76),                  # Should return 1 database row\n",
    "        select(MetalPrice).where(MetalPrice.id == 16),                  # Should return 1 database row\n",
    "    ]\n",
    "\n",
    "    tasks = []\n",
    "    for idx, query in enumerate(queries):\n",
    "        tasks.append(read_data(query))\n",
    "\n",
    "    # Concurrently execute all tasks\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a43d18b",
   "metadata": {},
   "source": [
    "Finally, we'll define the `main_read()` function to call `concurrent_reads()` and awaits its completion to print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c53e4605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to run concurrent reads\n",
    "async def main_read():\n",
    "    results = await concurrent_reads()    \n",
    "    # pp.pprint(results)\n",
    "    # Process results as needed    \n",
    "    for idx, data in enumerate(results):\n",
    "        # pp.pprint(rows)\n",
    "        print(f\"Results for query id = {idx}:\")\n",
    "        for row in data:\n",
    "            print(f\"ID: {row[0].id}, Metal: {row[0].metal}, Date: {row[0].date}, Price: {row[0].price}, MACD: {row[0].macd}, MACD_signal: {row[0].macd_signal}, RSI: {row[0].rsi}\")            \n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55539329-e5c5-4272-afed-f4467b9ff8dd",
   "metadata": {},
   "source": [
    "Note that the query results returned from `concurrent_reads()` is structurally complex compared to synschronous read in Question 3:\n",
    "- `results` is list of length 5, with each list item representing the results from each query executed cocurrently.\n",
    "- `data` is one of the list items within `results`. It contains a list of all the rows returned by a single data base query.\n",
    "- `row` is an item within `data`. It represents a single row of data returned from databaes query. Each `row` has a single-item tuple containing the data for that row, encapsulated as an instance of the `MetalPrice` class. `row[0]` is used to access that tuple item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "851e5a6d-911f-42bd-9303-20c4a8e953fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for query id = 0:\n",
      "ID: 525, Metal: COPPER, Date: 2021-01-01, Price: 7766.0, MACD: 262.12690234565434, MACD_signal: 267.8027105160701, RSI: 50.94816687737041\n",
      "ID: 526, Metal: ZINC, Date: 2021-01-01, Price: 2751.0, MACD: 66.30855054413951, MACD_signal: 73.89282576880589, RSI: 38.84514435695538\n",
      "ID: 1571, Metal: COPPER, Date: 2021-01-01, Price: 7766.0, MACD: 262.12690234565434, MACD_signal: 267.8027105160701, RSI: 50.94816687737041\n",
      "ID: 1572, Metal: ZINC, Date: 2021-01-01, Price: 2751.0, MACD: 66.30855054413951, MACD_signal: 73.89282576880589, RSI: 38.84514435695538\n",
      "\n",
      "Results for query id = 1:\n",
      "ID: 1, Metal: COPPER, Date: 2020-01-01, Price: 6174.0, MACD: 0.0, MACD_signal: 0.0, RSI: None\n",
      "\n",
      "Results for query id = 2:\n",
      "\n",
      "Results for query id = 3:\n",
      "ID: 76, Metal: ZINC, Date: 2020-02-20, Price: 2112.0, MACD: -27.50577707624916, MACD_signal: -10.99218094590205, RSI: 45.83508624316366\n",
      "\n",
      "Results for query id = 4:\n",
      "ID: 16, Metal: ZINC, Date: 2020-01-12, Price: 2770.0, MACD: 48.427135470621124, MACD_signal: 17.018710653716663, RSI: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the main_read() function using asyncio.run() in Jupyter notebook\n",
    "await main_read()\n",
    "\n",
    "# Run the main_read() function using asyncio.run() in Python script\n",
    "# asyncio.run(main_read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25c3ba26-8655-4686-a575-f411985311b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object AsyncEngine.dispose at 0x00000226BBB62E40>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Close and clean-up pooled connections.\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078542b9",
   "metadata": {},
   "source": [
    "# Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f2f5f1",
   "metadata": {},
   "source": [
    "[-] If the data is available offline, consider using **multiprocessing**. In an offline setting, such as when processing a large dataset or performing batch operations, multiprocessing can leverage multiple CPU cores to parallelize tasks effectively. In an online setting, such as when interacting with database server over the network, the emphasis is on responsiveness and asynchronous approach is well-suited. Combining multi-core processing and asynchronous processing is possible, albeit requiring careful coordination.\n",
    "\n",
    "[-] Consider using additional **database drivers**. While SQLAlchemy provides async support, performance is might be more limited compared to native async database drivers.\n",
    "\n",
    "[-] **Benchmark** to identify any performance bottlenecks of asynchronous operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271090c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
